{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qianyu-berkeley/NLP_study/blob/main/nlp_tasks/Fast_tokenizers_in_the_QA_pipeline_(PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AoA0I7Gq_ha"
      },
      "source": [
        "# Fast tokenizers in the QA pipeline (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2whDe8piq_hc"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H-lfhufXq_hc",
        "outputId": "e2df1aa3-9196-49af-e10d-b90d0ecd5a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[sentencepiece])\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, xxhash, dill, responses, multiprocess, huggingface-hub, transformers, datasets, evaluate\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 evaluate-0.4.0 huggingface-hub-0.16.4 multiprocess-0.70.15 responses-0.18.0 safetensors-0.3.3 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.32.0 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question and Answering use case using pipeline API\n",
        "\n",
        "* pipeline: `pipeline(\"question-answering\")`\n",
        "* Work with both short and long context"
      ],
      "metadata": {
        "id": "RlLG5Hpk0C5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iOQPJ1uYq_hd",
        "outputId": "56086fa2-bc81-4c5f-df8f-47bea963da4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "9a0ffa01f68348789c91bac1721f337f",
            "96e9c69d49714c68836bf3c174a25a77",
            "45b19d9d26b3405faac6046f6bbc5365",
            "944e7a58472e4648a65b7b30a20d0916",
            "19899db587264d62bb5a97247ddd07ec",
            "66d020dc19ef47e9a1e2630a26fac4d0",
            "d9b8c164bc9246de8132b3c67e954e27",
            "475b81f5cab04ec39048d1b12f2a92b0",
            "4075c55818ae4a47ae0c4e462471552f",
            "c20250168cbc4249a5c06bec7d03131d",
            "67ed1a0fb9bd4c1683a04461f3fd89e6",
            "1fdc4112589d4a6a8097427f85eba74d",
            "b7745844d2824a06afb73cd62a791d28",
            "8d5f41970e4a42df86fe10cecf0077ec",
            "4e0605a2478c42e8891a7372572e43e4",
            "99dcac0e5573452cb3d0255861f2a0f0",
            "0ee3beddef6447e084567089b935e972",
            "87cc68f80b0847f39005b1de86397e70",
            "3c229a6a087e4b2585342a253a48be3b",
            "ac404154a1894be59fc5c16281b883d8",
            "f65db6ca6346440b9b0e41504714a020",
            "8d9322c9e8ac440bad8f269fc16f4ed8",
            "5e6413281d8949c49f8e5ea123ccce6e",
            "a44fb43d052442e482835fa792959c46",
            "75723f1a305940e292f7bf53f59230a2",
            "513bda5b002e4c92b40087ab89ab9287",
            "5ac85885df38444796d08239b8a76db9",
            "84cfe2bcb78e45d3b1fe1f1c07541c31",
            "6a7cb6f217f84f68935bab1811ca0c31",
            "c1539e653df64b078f99366f1ebdac00",
            "cdcc7be1b4654e2ea62a9776932ac763",
            "e2affba35c914e0f8725437a76c7bd48",
            "0fe2ccc8d9694041b6c74a2a5c177dc2",
            "a9cf94e693eb43889cee484d422103be",
            "3507232142aa40b585626533f58efda9",
            "7d8c85946b984c9fb6ee552db31b477a",
            "8b560f88f98b40a78a952314b4e408ea",
            "024942901cd64b2ab2804aaff3b160eb",
            "2a09b053cbd74e7ea8f9d1ee3ed3644c",
            "9b68dc56cf664301836d3ccc95c2c812",
            "608f60e52b704449a584e9f4789fd003",
            "d41246ba284d40b6b8e77675b24ff302",
            "46798123a56a4869b8b4d11695762940",
            "a00c31b1b6354c6c9b6099ea441f3434",
            "acac4e83871a4257a602e8dcfbd9d79b",
            "6229378e04cd4873acf9d87fee790a4b",
            "89cfcfa410d24e40a7b014a4086ffdfe",
            "a42adddc31f74bf6871cb28fb2fd2323",
            "093558bcbed44091b982001e2d853a24",
            "d41d6870b745433db41a1dad940b22c9",
            "6a48686555be414bbefc2d743de51b9a",
            "470408783ac943ebbad6251e07856890",
            "f7f1b201ba1b4267947858aee245f2f4",
            "917b924fd48d4d33ae96147faa8de358",
            "271ae459b07346fba698c29d0f73c6e6"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a0ffa01f68348789c91bac1721f337f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fdc4112589d4a6a8097427f85eba74d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e6413281d8949c49f8e5ea123ccce6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9cf94e693eb43889cee484d422103be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acac4e83871a4257a602e8dcfbd9d79b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9802603125572205,\n",
              " 'start': 78,\n",
              " 'end': 106,\n",
              " 'answer': 'Jax, PyTorch, and TensorFlow'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "context = \"\"\"\n",
        "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "question = \"Which deep learning libraries back 🤗 Transformers?\"\n",
        "question_answerer(question=question, context=context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jTg_SZdxq_hd",
        "outputId": "44d7ba01-0cff-4807-8243-d38159c12fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9714871048927307,\n",
              " 'start': 1892,\n",
              " 'end': 1919,\n",
              " 'answer': 'Jax, PyTorch and TensorFlow'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "long_context = \"\"\"\n",
        "🤗 Transformers: State of the Art NLP\n",
        "\n",
        "🤗 Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
        "question answering, summarization, translation, text generation and more in over 100 languages.\n",
        "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
        "\n",
        "🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
        "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
        "can be modified to enable quick research experiments.\n",
        "\n",
        "Why should I use transformers?\n",
        "\n",
        "1. Easy-to-use state-of-the-art models:\n",
        "  - High performance on NLU and NLG tasks.\n",
        "  - Low barrier to entry for educators and practitioners.\n",
        "  - Few user-facing abstractions with just three classes to learn.\n",
        "  - A unified API for using all our pretrained models.\n",
        "  - Lower compute costs, smaller carbon footprint:\n",
        "\n",
        "2. Researchers can share trained models instead of always retraining.\n",
        "  - Practitioners can reduce compute time and production costs.\n",
        "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
        "\n",
        "3. Choose the right framework for every part of a model's lifetime:\n",
        "  - Train state-of-the-art models in 3 lines of code.\n",
        "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
        "  - Seamlessly pick the right framework for training, evaluation and production.\n",
        "\n",
        "4. Easily customize a model or an example to your needs:\n",
        "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
        "  - Model internals are exposed as consistently as possible.\n",
        "  - Model files can be used independently of the library for quick experiments.\n",
        "\n",
        "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "question_answerer(question=question, context=long_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question and Answering use case using AutoModel API"
      ],
      "metadata": {
        "id": "hLkUpFk80hpw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pWtjMUyRq_he"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z5M7V3j1q_he",
        "outputId": "03ddeb39-1b05-4812-8b54-f34750b5b7d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 67]) torch.Size([1, 67])\n"
          ]
        }
      ],
      "source": [
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "print(start_logits.shape, end_logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- start logits ------\")\n",
        "print(start_logits)\n",
        "print(\"----- end logits ------\")\n",
        "print(end_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0VDgVPp1jE7",
        "outputId": "23e60074-e154-4223-8cd9-80b5600b8151"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- start logits ------\n",
            "tensor([[-4.4952, -6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368,\n",
            "         -5.9199, -5.4193, -1.5920, -1.0857, -5.0981, -2.9331, -3.4070,  2.2467,\n",
            "          5.1563, -1.3602, -2.2209, -0.9686, -4.8112, -2.2527,  1.4383, 10.1211,\n",
            "         -1.5311,  2.2685, -1.8951, -2.2108, -4.2142, -2.5571, -2.3252, -2.6046,\n",
            "          1.7047, -1.9867, -1.7211, -0.5415, -2.0239, -4.4246, -5.1012, -4.4966,\n",
            "         -7.8940, -6.7200, -4.6759, -6.3278, -4.8339, -5.1839, -3.3724, -7.4120,\n",
            "         -8.1542, -4.4871, -7.4659, -4.3293, -4.2293, -3.1903, -7.9467, -5.2665,\n",
            "         -7.5902, -5.0570, -7.4476, -7.9083, -6.5951, -7.4061, -8.8821, -7.6749,\n",
            "         -6.9879, -7.0466, -5.4193]], grad_fn=<CloneBackward0>)\n",
            "----- end logits ------\n",
            "tensor([[-2.3958e+00, -7.0978e+00, -7.0745e+00, -6.3676e+00, -5.9532e+00,\n",
            "         -7.9585e+00, -7.1869e+00, -3.6494e+00, -6.9677e+00, -5.1421e+00,\n",
            "         -3.1757e+00, -1.1649e+00, -7.0748e+00, -5.2875e+00, -6.8611e+00,\n",
            "         -5.1769e+00,  3.7892e+00, -4.4408e+00, -7.6687e-01, -3.9180e+00,\n",
            "         -2.1634e+00,  1.8116e+00, -1.4678e+00,  2.0508e+00,  1.5404e-03,\n",
            "         -1.5531e+00, -6.9470e-01, -1.3466e+00, -1.6879e+00,  4.0826e+00,\n",
            "          1.1467e+00, -3.7881e-01,  6.0774e-01,  1.2281e+00,  5.8202e-01,\n",
            "          1.0657e+01,  5.8794e+00, -5.7342e+00, -7.0719e+00, -6.8077e+00,\n",
            "         -7.1513e+00, -5.3228e+00, -3.4305e+00, -4.2575e+00,  2.2268e+00,\n",
            "         -4.1297e-01, -6.8944e+00, -7.9381e+00, -8.3298e+00, -5.6078e+00,\n",
            "         -8.9589e+00, -5.5772e+00, -5.7309e+00, -1.9592e+00, -7.8078e+00,\n",
            "         -2.3823e+00, -7.2457e+00, -6.1642e+00, -4.2830e+00, -8.0948e+00,\n",
            "         -8.0364e+00, -4.5566e+00, -7.6585e+00, -7.3241e+00, -2.2402e+00,\n",
            "         -1.8462e+00, -5.1421e+00]], grad_fn=<CloneBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking the context and `[SEP]` characters except `[CLS]` token\n",
        "\n",
        "* Some QA models use `[CLS]` to indicate that the answer is not in the context.\n",
        "* To apply a softmax afterward, we need to replace the logits we masked with a large negative number. e.g. use -10000, to get 0.0"
      ],
      "metadata": {
        "id": "OlRnWPjZ1z4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cdAQQ63yq_he"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "sequence_ids = inputs.sequence_ids()\n",
        "# Mask everything apart from the tokens of the context\n",
        "mask = [i != 1 for i in sequence_ids]\n",
        "# Unmask the [CLS] token\n",
        "mask[0] = False\n",
        "mask = torch.tensor(mask)[None]\n",
        "\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wXU5JBIsq_hf"
      },
      "outputs": [],
      "source": [
        "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)[0]\n",
        "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"------- start probability --------\")\n",
        "print(start_probabilities.shape)\n",
        "print(start_probabilities)\n",
        "print(\"------- end probability --------\")\n",
        "print(end_probabilities.shape)\n",
        "print(end_probabilities)"
      ],
      "metadata": {
        "id": "bt08umar6Gym",
        "outputId": "42f274b1-7cf7-4493-b55a-7e6b1d92fcbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- start probability --------\n",
            "torch.Size([67])\n",
            "tensor([4.4531e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1185e-06, 1.3470e-05,\n",
            "        2.4368e-07, 2.1236e-06, 1.3220e-06, 3.7722e-04, 6.9219e-03, 1.0237e-05,\n",
            "        4.3289e-06, 1.5143e-05, 3.2463e-07, 4.1933e-06, 1.6808e-04, 9.9179e-01,\n",
            "        8.6288e-06, 3.8557e-04, 5.9956e-06, 4.3725e-06, 5.8977e-07, 3.0929e-06,\n",
            "        3.8999e-06, 2.9493e-06, 2.1940e-04, 5.4713e-06, 7.1354e-06, 2.3212e-05,\n",
            "        5.2711e-06, 4.7788e-07, 2.4291e-07, 4.4467e-07, 1.4879e-08, 4.8133e-08,\n",
            "        3.7169e-07, 7.1242e-08, 3.1735e-07, 2.2365e-07, 1.3685e-06, 2.4093e-08,\n",
            "        1.1470e-08, 4.4891e-07, 2.2828e-08, 5.2562e-07, 5.8092e-07, 1.6419e-06,\n",
            "        1.4114e-08, 2.0591e-07, 2.0161e-08, 2.5390e-07, 2.3251e-08, 1.4667e-08,\n",
            "        5.4533e-08, 2.4235e-08, 5.5390e-09, 1.8524e-08, 3.6818e-08, 3.4721e-08,\n",
            "        0.0000e+00], grad_fn=<SelectBackward0>)\n",
            "------- end probability --------\n",
            "torch.Size([67])\n",
            "tensor([2.1185e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7129e-07, 7.2546e-06,\n",
            "        1.9679e-08, 1.1754e-07, 2.4366e-08, 1.3130e-07, 1.0284e-03, 2.7411e-07,\n",
            "        1.0801e-05, 4.6233e-07, 2.6730e-06, 1.4233e-04, 5.3586e-06, 1.8078e-04,\n",
            "        2.3292e-05, 4.9207e-06, 1.1610e-05, 6.0494e-06, 4.3002e-06, 1.3790e-03,\n",
            "        7.3201e-05, 1.5923e-05, 4.2704e-05, 7.9413e-05, 4.1620e-05, 9.8838e-01,\n",
            "        8.3161e-03, 7.5197e-08, 1.9735e-08, 2.5704e-08, 1.8229e-08, 1.1346e-07,\n",
            "        7.5278e-07, 3.2926e-07, 2.1558e-04, 1.5388e-05, 2.3568e-08, 8.2993e-09,\n",
            "        5.6096e-09, 8.5331e-08, 2.9904e-09, 8.7980e-08, 7.5447e-08, 3.2784e-06,\n",
            "        9.4549e-09, 2.1473e-06, 1.6586e-08, 4.8915e-08, 3.2096e-07, 7.0959e-09,\n",
            "        7.5224e-09, 2.4413e-07, 1.0978e-08, 1.5336e-08, 2.4753e-06, 3.6704e-06,\n",
            "        0.0000e+00], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(start_probabilities[:, None].shape)\n",
        "print(end_probabilities[None, :].shape)"
      ],
      "metadata": {
        "id": "sRsU547dHuUL",
        "outputId": "f7cf3e91-0959-4876-e56a-e45c0cd2a3d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([67, 1])\n",
            "torch.Size([1, 67])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the best start and end index\n",
        "\n",
        "* To prevent start index larger than end index from argmax (meaning to avoid first word of the answer behind the last word in the text), We will compute the probabilities of each possible start_index and end_index where start_index <= end_index, then take the tuple (start_index, end_index) with the highest probability.\n",
        "* compute all the products `start_probabilities[start_index]×end_probabilities[end_index]` where start_index <= end_index.\n",
        "* Then we’ll mask the values where start_index > end_index by setting them to 0 (the other probabilities are all positive numbers). The `torch.triu()` function returns the upper triangular part of the 2D tensor passed as an argument, so it will do that masking for us because start_index <= end_index at the upper triangle"
      ],
      "metadata": {
        "id": "kF3I7fOd3tEK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nMSLVeXrq_hf",
        "outputId": "82bc272c-950d-4b49-8b52-cca44ac31b2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Score ----\n",
            "torch.Size([67, 67])\n",
            "tensor([[9.4340e-13, 0.0000e+00, 0.0000e+00,  ..., 1.1023e-12, 1.6345e-12,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [7.8000e-14, 0.0000e+00, 0.0000e+00,  ..., 9.1135e-14, 1.3514e-13,\n",
            "         0.0000e+00],\n",
            "        [7.3557e-14, 0.0000e+00, 0.0000e+00,  ..., 8.5944e-14, 1.2744e-13,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "scores = start_probabilities[:, None] * end_probabilities[None, :]\n",
        "print(\"---- Score ----\")\n",
        "print(scores.shape)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nI6kPOswq_hf",
        "outputId": "dd5f1493-696d-437f-ce3d-1d92a1542f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- upper triangle only score\n",
            "torch.Size([67, 67])\n",
            "tensor([[9.4340e-13, 0.0000e+00, 0.0000e+00,  ..., 1.1023e-12, 1.6345e-12,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1135e-14, 1.3514e-13,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.2744e-13,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<TriuBackward0>)\n"
          ]
        }
      ],
      "source": [
        "scores = torch.triu(scores)\n",
        "print(\"---- upper triangle only score\")\n",
        "print(scores.shape)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8FOdXwPdq_hf",
        "outputId": "c87be90d-5701-4b0d-f93f-7e7aebee2eb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_index: 1576\n",
            "(start_index, end_index): (23, 35)\n",
            "tensor(0.9803, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "max_index = scores.argmax().item()\n",
        "print(f\"max_index: {max_index}\")\n",
        "start_index = max_index // scores.shape[1]\n",
        "end_index = max_index % scores.shape[1]\n",
        "print(f\"(start_index, end_index): ({start_index}, {end_index})\")\n",
        "print(scores[start_index, end_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "shwGfyiCq_hf"
      },
      "outputs": [],
      "source": [
        "inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=True)\n",
        "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "start_char, _ = offsets[start_index]\n",
        "_, end_char = offsets[end_index]\n",
        "answer = context[start_char:end_char]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lqPrhIfxq_hf",
        "outputId": "d2e24e52-878c-4d53-c714-2d36327b7e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Jax, PyTorch, and TensorFlow',\n",
              " 'start': 78,\n",
              " 'end': 106,\n",
              " 'score': tensor(0.9803, grad_fn=<SelectBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "result = {\n",
        "    \"answer\": answer,\n",
        "    \"start\": start_char,\n",
        "    \"end\": end_char,\n",
        "    \"score\": scores[start_index, end_index],\n",
        "}\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find top 5 answers\n",
        "\n",
        "* Using the same process to find the top 5 start, end index\n",
        "* Then get the tokens span between those indexs"
      ],
      "metadata": {
        "id": "JAU4GMYE47eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values, indexes = scores.flatten().topk(k=5)\n",
        "print(values)\n",
        "print(indexes)"
      ],
      "metadata": {
        "id": "PYRyU2VhbhXv",
        "outputId": "6b2f9355-6a92-4fd2-d1b7-df9d604eed17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.8026e-01, 8.2478e-03, 6.8415e-03, 1.3677e-03, 3.8109e-04],\n",
            "       grad_fn=<TopkBackward0>)\n",
            "tensor([1576, 1577, 1107, 1570, 1710])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_indexes = []\n",
        "\n",
        "for i in range(len(indexes)):\n",
        "    s = indexes[i].item() // scores.shape[1]\n",
        "    e = indexes[i].item() % scores.shape[1]\n",
        "    print(f\" top {i+1} (start_index, end_index): ({s}, {e})\")\n",
        "    top5_indexes.append((s, e))\n",
        "print(top5_indexes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAQWHogo5fdk",
        "outputId": "2ae783e3-c303-4de7-b7f4-1eaf7a45768b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " top 1 (start_index, end_index): (23, 35)\n",
            " top 2 (start_index, end_index): (23, 36)\n",
            " top 3 (start_index, end_index): (16, 35)\n",
            " top 4 (start_index, end_index): (23, 29)\n",
            " top 5 (start_index, end_index): (25, 35)\n",
            "[(23, 35), (23, 36), (16, 35), (23, 29), (25, 35)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s, e in top5_indexes:\n",
        "    start_char, _ = offsets[s]\n",
        "    _, end_char = offsets[e]\n",
        "    answer = context[start_char:end_char]\n",
        "    result = {\n",
        "        \"answer\": answer,\n",
        "        \"start\": start_char,\n",
        "        \"end\": end_char,\n",
        "        \"score\": scores[s, e],\n",
        "    }\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDIU1a6x7N9-",
        "outputId": "92145067-a621-4bca-f9c9-47dce942922e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': 'Jax, PyTorch, and TensorFlow', 'start': 78, 'end': 106, 'score': tensor(0.9803, grad_fn=<SelectBackward0>)}\n",
            "{'answer': 'Jax, PyTorch, and TensorFlow —', 'start': 78, 'end': 108, 'score': tensor(0.0082, grad_fn=<SelectBackward0>)}\n",
            "{'answer': 'three most popular deep learning libraries — Jax, PyTorch, and TensorFlow', 'start': 33, 'end': 106, 'score': tensor(0.0068, grad_fn=<SelectBackward0>)}\n",
            "{'answer': 'Jax, PyTorch', 'start': 78, 'end': 90, 'score': tensor(0.0014, grad_fn=<SelectBackward0>)}\n",
            "{'answer': 'PyTorch, and TensorFlow', 'start': 83, 'end': 106, 'score': tensor(0.0004, grad_fn=<SelectBackward0>)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoModel API for Long Context\n",
        "\n",
        "* Use `trunction=\"only_second\"` strategy to truncate context\n",
        "* To avoid loss of answer, use `return_overflowing_tokens=True` option in tokenizer"
      ],
      "metadata": {
        "id": "TwnztoOI5I3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3nXGupZjq_hf",
        "outputId": "072eba09-8121-4869-8298-f05999b51367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "461\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(question, long_context)\n",
        "print(len(inputs[\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZvvZUK8Mq_hf",
        "outputId": "f35524a5-4a05-4477-b339-761435c16cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] [UNK] Transformers : State of the Art NLP [UNK] Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more in over 100 languages. Its aim is to make cutting - edge NLP easier to use for everyone. [UNK] Transformers provides APIs to quickly download and use those pretrained models on a given text, fine - tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments. Why should I use transformers? 1. Easy - to - use state - of - the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and practitioners. - Few user - facing abstractions with just three classes to learn. - A unified API for using all our pretrained models. - Lower compute costs, smaller carbon footprint : 2. Researchers can share trained models instead of always retraining. - Practitioners can reduce compute time and production costs. - Dozens of architectures with over 10, 000 pretrained models, some in more than 100 languages. 3. Choose the right framework for every part of a model's lifetime : - Train state - of - the - art models in 3 lines of code. - Move a single model between TF2. 0 / PyTorch frameworks at will. - Seamlessly pick the right framework for training, evaluation and production. 4. Easily customize a model or an example to your needs : - We provide examples for each architecture to reproduce the results published by its original authors. - Model internal [SEP]\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(question, long_context, max_length=384, truncation=\"only_second\")\n",
        "print(tokenizer.decode(inputs[\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q8b6O8v3q_hf",
        "outputId": "68c61686-8be6-404d-d87a-33eee2c774ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] This sentence is not [SEP]\n",
            "[CLS] is not too long [SEP]\n",
            "[CLS] too long but we [SEP]\n",
            "[CLS] but we are going [SEP]\n",
            "[CLS] are going to split [SEP]\n",
            "[CLS] to split it anyway [SEP]\n",
            "[CLS] it anyway. [SEP]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"This sentence is not too long but we are going to split it anyway.\"\n",
        "inputs = tokenizer(\n",
        "    sentence, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
        ")\n",
        "\n",
        "for ids in inputs[\"input_ids\"]:\n",
        "    print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mY0n9jekq_hg",
        "outputId": "1ffd4461-8109-4e7d-bfee-90a47eda323c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])\n"
          ]
        }
      ],
      "source": [
        "print(inputs.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ji2xrzbSq_hg",
        "outputId": "b916d0b8-1982-4c79-f1db-43d280771c96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X9o5LA9iq_hg",
        "outputId": "d3208dd5-bdd3-48e6-e9ae-ed966b5af089",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"This sentence is not too long but we are going to split it anyway.\",\n",
        "    \"This sentence is shorter but will still get split.\",\n",
        "]\n",
        "inputs = tokenizer(\n",
        "    sentences, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
        ")\n",
        "\n",
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OdhzdU0rq_hg"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\n",
        "    question,\n",
        "    long_context,\n",
        "    stride=128,\n",
        "    max_length=384,\n",
        "    padding=\"longest\",\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Those inputs will contain the input IDs and attention masks the model expects, as well as the offsets and the `overflow_to_sample_mapping`. Since those two are not parameters used by the model, we’ll pop them out of the inputs (and we won’t store the map, since it’s not useful here) before converting it to a tensor:"
      ],
      "metadata": {
        "id": "HvTxO0L-_yJw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cBum0Wh0q_hg",
        "outputId": "b05191ac-1ab9-4475-e5ae-b51ba63f280e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 384])\n"
          ]
        }
      ],
      "source": [
        "_ = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "offsets = inputs.pop(\"offset_mapping\")\n",
        "\n",
        "inputs = inputs.convert_to_tensors(\"pt\")\n",
        "print(inputs[\"input_ids\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dOUgp9l0q_hg",
        "outputId": "d6ac197b-96e7-4464-ed45-820825c7181b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 384]) torch.Size([2, 384])\n"
          ]
        }
      ],
      "source": [
        "outputs = model(**inputs)\n",
        "\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "print(start_logits.shape, end_logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notices the first dimension of the tensor is 2 now as we create chunks**"
      ],
      "metadata": {
        "id": "sk-8WgalANE9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XBzHue3Lq_hg"
      },
      "outputs": [],
      "source": [
        "sequence_ids = inputs.sequence_ids()\n",
        "# Mask everything apart from the tokens of the context\n",
        "mask = [i != 1 for i in sequence_ids]\n",
        "# Unmask the [CLS] token\n",
        "mask[0] = False\n",
        "# Mask all the [PAD] tokens\n",
        "mask = torch.logical_or(torch.tensor(mask)[None], (inputs[\"attention_mask\"] == 0))\n",
        "\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "u90g_atAq_hg"
      },
      "outputs": [],
      "source": [
        "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)\n",
        "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "FoDl4RH1q_hg",
        "outputId": "4a33e5ff-82b8-4df4-9aeb-1f6e8b33ca29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 18, 0.3386707305908203), (173, 184, 0.9714868664741516)]\n"
          ]
        }
      ],
      "source": [
        "candidates = []\n",
        "for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n",
        "    scores = start_probs[:, None] * end_probs[None, :]\n",
        "    idx = torch.triu(scores).argmax().item()\n",
        "\n",
        "    start_idx = idx // scores.shape[1]\n",
        "    end_idx = idx % scores.shape[1]\n",
        "    score = scores[start_idx, end_idx].item()\n",
        "    candidates.append((start_idx, end_idx, score))\n",
        "\n",
        "print(candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lNrMizBBq_hg",
        "outputId": "4f7ba87c-d80a-4964-ff7a-b790e9a3b13e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': '\\n🤗 Transformers: State of the Art NLP', 'start': 0, 'end': 37, 'score': 0.3386707305908203}\n",
            "{'answer': 'Jax, PyTorch and TensorFlow', 'start': 1892, 'end': 1919, 'score': 0.9714868664741516}\n"
          ]
        }
      ],
      "source": [
        "for candidate, offset in zip(candidates, offsets):\n",
        "    start_token, end_token, score = candidate\n",
        "    start_char, _ = offset[start_token]\n",
        "    _, end_char = offset[end_token]\n",
        "    answer = long_context[start_char:end_char]\n",
        "    result = {\"answer\": answer, \"start\": start_char, \"end\": end_char, \"score\": score}\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get top 5 most likely answer (not per chunk)"
      ],
      "metadata": {
        "id": "a992kTjiA8XO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "outputId": "c2cd7b5f-94c7-4c6f-beff-37e5f93b9c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nl6OOg7HTMq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " top 1 (start_index, end_index): (0, 18)\n",
            " top 2 (start_index, end_index): (0, 0)\n",
            " top 3 (start_index, end_index): (13, 18)\n",
            " top 4 (start_index, end_index): (17, 18)\n",
            " top 5 (start_index, end_index): (0, 19)\n",
            " top 1 (start_index, end_index): (173, 184)\n",
            " top 2 (start_index, end_index): (173, 185)\n",
            " top 3 (start_index, end_index): (166, 184)\n",
            " top 4 (start_index, end_index): (173, 193)\n",
            " top 5 (start_index, end_index): (173, 179)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0, 18, 0.3386707305908203),\n",
              " (0, 0, 0, 0.22401131689548492),\n",
              " (0, 13, 18, 0.14949698746204376),\n",
              " (0, 17, 18, 0.013705562800168991),\n",
              " (0, 0, 19, 0.011742623522877693),\n",
              " (1, 173, 184, 0.9714868664741516),\n",
              " (1, 173, 185, 0.015565156936645508),\n",
              " (1, 166, 184, 0.007162699941545725),\n",
              " (1, 173, 193, 0.0008136184187605977),\n",
              " (1, 173, 179, 0.0007655616500414908)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "candidates = []\n",
        "chunk = 0\n",
        "for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n",
        "    scores = start_probs[:, None] * end_probs[None, :]\n",
        "    scores = torch.triu(scores)\n",
        "    values, indexes = scores.flatten().topk(k=5)\n",
        "    top5_indexes = []\n",
        "    for i in range(len(indexes)):\n",
        "        s = indexes[i].item() // scores.shape[1]\n",
        "        e = indexes[i].item() % scores.shape[1]\n",
        "        print(f\" top {i+1} (start_index, end_index): ({s}, {e})\")\n",
        "        score = scores[s, e].item()\n",
        "        candidates.append((chunk, s, e, score))\n",
        "    chunk += 1\n",
        "\n",
        "candidates"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidates.sort(key=lambda x: x[-1], reverse=True)\n",
        "candidates_top5 = candidates[:5]\n",
        "candidates_top5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wi_aYlWs6l",
        "outputId": "9342c153-71b3-47e2-a51a-daaae1ac9d91"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 173, 184, 0.9714868664741516),\n",
              " (0, 0, 18, 0.3386707305908203),\n",
              " (0, 0, 0, 0.22401131689548492),\n",
              " (0, 13, 18, 0.14949698746204376),\n",
              " (1, 173, 185, 0.015565156936645508)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for candidate in candidates_top5:\n",
        "    offset_idx, start_token, end_token, score = candidate\n",
        "    offset = offsets[offset_idx]\n",
        "    start_char, _ = offset[start_token]\n",
        "    _, end_char = offset[end_token]\n",
        "    answer = long_context[start_char:end_char]\n",
        "    result = {\"answer\": answer, \"start\": start_char, \"end\": end_char, \"score\": score}\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4j9SvsnG_JX",
        "outputId": "2dde9dee-c9b2-4a4a-8891-379345a3109e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': 'Jax, PyTorch and TensorFlow', 'start': 1892, 'end': 1919, 'score': 0.9714868664741516}\n",
            "{'answer': '\\n🤗 Transformers: State of the Art NLP', 'start': 0, 'end': 37, 'score': 0.3386707305908203}\n",
            "{'answer': '', 'start': 0, 'end': 0, 'score': 0.22401131689548492}\n",
            "{'answer': 'State of the Art NLP', 'start': 17, 'end': 37, 'score': 0.14949698746204376}\n",
            "{'answer': 'Jax, PyTorch and TensorFlow —', 'start': 1892, 'end': 1921, 'score': 0.015565156936645508}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a0ffa01f68348789c91bac1721f337f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96e9c69d49714c68836bf3c174a25a77",
              "IPY_MODEL_45b19d9d26b3405faac6046f6bbc5365",
              "IPY_MODEL_944e7a58472e4648a65b7b30a20d0916"
            ],
            "layout": "IPY_MODEL_19899db587264d62bb5a97247ddd07ec"
          }
        },
        "96e9c69d49714c68836bf3c174a25a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d020dc19ef47e9a1e2630a26fac4d0",
            "placeholder": "​",
            "style": "IPY_MODEL_d9b8c164bc9246de8132b3c67e954e27",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "45b19d9d26b3405faac6046f6bbc5365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_475b81f5cab04ec39048d1b12f2a92b0",
            "max": 473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4075c55818ae4a47ae0c4e462471552f",
            "value": 473
          }
        },
        "944e7a58472e4648a65b7b30a20d0916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c20250168cbc4249a5c06bec7d03131d",
            "placeholder": "​",
            "style": "IPY_MODEL_67ed1a0fb9bd4c1683a04461f3fd89e6",
            "value": " 473/473 [00:00&lt;00:00, 19.2kB/s]"
          }
        },
        "19899db587264d62bb5a97247ddd07ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d020dc19ef47e9a1e2630a26fac4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b8c164bc9246de8132b3c67e954e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "475b81f5cab04ec39048d1b12f2a92b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4075c55818ae4a47ae0c4e462471552f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c20250168cbc4249a5c06bec7d03131d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ed1a0fb9bd4c1683a04461f3fd89e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fdc4112589d4a6a8097427f85eba74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7745844d2824a06afb73cd62a791d28",
              "IPY_MODEL_8d5f41970e4a42df86fe10cecf0077ec",
              "IPY_MODEL_4e0605a2478c42e8891a7372572e43e4"
            ],
            "layout": "IPY_MODEL_99dcac0e5573452cb3d0255861f2a0f0"
          }
        },
        "b7745844d2824a06afb73cd62a791d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee3beddef6447e084567089b935e972",
            "placeholder": "​",
            "style": "IPY_MODEL_87cc68f80b0847f39005b1de86397e70",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "8d5f41970e4a42df86fe10cecf0077ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c229a6a087e4b2585342a253a48be3b",
            "max": 260782156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac404154a1894be59fc5c16281b883d8",
            "value": 260782156
          }
        },
        "4e0605a2478c42e8891a7372572e43e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f65db6ca6346440b9b0e41504714a020",
            "placeholder": "​",
            "style": "IPY_MODEL_8d9322c9e8ac440bad8f269fc16f4ed8",
            "value": " 261M/261M [00:01&lt;00:00, 144MB/s]"
          }
        },
        "99dcac0e5573452cb3d0255861f2a0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee3beddef6447e084567089b935e972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cc68f80b0847f39005b1de86397e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c229a6a087e4b2585342a253a48be3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac404154a1894be59fc5c16281b883d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f65db6ca6346440b9b0e41504714a020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9322c9e8ac440bad8f269fc16f4ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e6413281d8949c49f8e5ea123ccce6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a44fb43d052442e482835fa792959c46",
              "IPY_MODEL_75723f1a305940e292f7bf53f59230a2",
              "IPY_MODEL_513bda5b002e4c92b40087ab89ab9287"
            ],
            "layout": "IPY_MODEL_5ac85885df38444796d08239b8a76db9"
          }
        },
        "a44fb43d052442e482835fa792959c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84cfe2bcb78e45d3b1fe1f1c07541c31",
            "placeholder": "​",
            "style": "IPY_MODEL_6a7cb6f217f84f68935bab1811ca0c31",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "75723f1a305940e292f7bf53f59230a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1539e653df64b078f99366f1ebdac00",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdcc7be1b4654e2ea62a9776932ac763",
            "value": 29
          }
        },
        "513bda5b002e4c92b40087ab89ab9287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2affba35c914e0f8725437a76c7bd48",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe2ccc8d9694041b6c74a2a5c177dc2",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.25kB/s]"
          }
        },
        "5ac85885df38444796d08239b8a76db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84cfe2bcb78e45d3b1fe1f1c07541c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7cb6f217f84f68935bab1811ca0c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1539e653df64b078f99366f1ebdac00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdcc7be1b4654e2ea62a9776932ac763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2affba35c914e0f8725437a76c7bd48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe2ccc8d9694041b6c74a2a5c177dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9cf94e693eb43889cee484d422103be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3507232142aa40b585626533f58efda9",
              "IPY_MODEL_7d8c85946b984c9fb6ee552db31b477a",
              "IPY_MODEL_8b560f88f98b40a78a952314b4e408ea"
            ],
            "layout": "IPY_MODEL_024942901cd64b2ab2804aaff3b160eb"
          }
        },
        "3507232142aa40b585626533f58efda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a09b053cbd74e7ea8f9d1ee3ed3644c",
            "placeholder": "​",
            "style": "IPY_MODEL_9b68dc56cf664301836d3ccc95c2c812",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "7d8c85946b984c9fb6ee552db31b477a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608f60e52b704449a584e9f4789fd003",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d41246ba284d40b6b8e77675b24ff302",
            "value": 213450
          }
        },
        "8b560f88f98b40a78a952314b4e408ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46798123a56a4869b8b4d11695762940",
            "placeholder": "​",
            "style": "IPY_MODEL_a00c31b1b6354c6c9b6099ea441f3434",
            "value": " 213k/213k [00:00&lt;00:00, 3.22MB/s]"
          }
        },
        "024942901cd64b2ab2804aaff3b160eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a09b053cbd74e7ea8f9d1ee3ed3644c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b68dc56cf664301836d3ccc95c2c812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "608f60e52b704449a584e9f4789fd003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41246ba284d40b6b8e77675b24ff302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46798123a56a4869b8b4d11695762940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00c31b1b6354c6c9b6099ea441f3434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acac4e83871a4257a602e8dcfbd9d79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6229378e04cd4873acf9d87fee790a4b",
              "IPY_MODEL_89cfcfa410d24e40a7b014a4086ffdfe",
              "IPY_MODEL_a42adddc31f74bf6871cb28fb2fd2323"
            ],
            "layout": "IPY_MODEL_093558bcbed44091b982001e2d853a24"
          }
        },
        "6229378e04cd4873acf9d87fee790a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41d6870b745433db41a1dad940b22c9",
            "placeholder": "​",
            "style": "IPY_MODEL_6a48686555be414bbefc2d743de51b9a",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "89cfcfa410d24e40a7b014a4086ffdfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_470408783ac943ebbad6251e07856890",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7f1b201ba1b4267947858aee245f2f4",
            "value": 435797
          }
        },
        "a42adddc31f74bf6871cb28fb2fd2323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917b924fd48d4d33ae96147faa8de358",
            "placeholder": "​",
            "style": "IPY_MODEL_271ae459b07346fba698c29d0f73c6e6",
            "value": " 436k/436k [00:00&lt;00:00, 14.1MB/s]"
          }
        },
        "093558bcbed44091b982001e2d853a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41d6870b745433db41a1dad940b22c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a48686555be414bbefc2d743de51b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "470408783ac943ebbad6251e07856890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7f1b201ba1b4267947858aee245f2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "917b924fd48d4d33ae96147faa8de358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271ae459b07346fba698c29d0f73c6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}